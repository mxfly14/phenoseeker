{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phenoseeker import EmbeddingManager\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_meta = pd.read_parquet(\"/projects/cpjump1/jump/load_data/test_training.parquet\")\n",
    "df_meta = pd.read_parquet(\"/projects/cpjump1/jump/load_data/final\")\n",
    "df_small_meta = pd.read_parquet(\"/projects/cpjump1/jump/load_data/small_training.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"/projects/cpjump1/jump/load_data/load_data_with_metadata/Metadata_Source=source_6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from phenoseeker import EmbeddingManager\n",
    "\n",
    "\n",
    "class EmbeddingsEvaluator:\n",
    "    \"\"\"\n",
    "    A class that encapsulates the evaluation pipeline for embeddings.\n",
    "\n",
    "    The pipeline includes:\n",
    "      - Loading the embeddings using a specified entity and embeddings name.\n",
    "      - Grouping the embeddings by a specified key (e.g., \"well\") and keeping selected\n",
    "        columns.\n",
    "      - Applying a spherizing transform and an inverse normalization transform.\n",
    "      - Filtering embeddings using a provided condition.\n",
    "      - Computing evaluation metrics (e.g., maps and lisi).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        metadata_path: Path,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initializes the evaluator.\n",
    "\n",
    "        Args:\n",
    "            metadata_path (Path): Path to the metadata.\n",
    "            entity (str): The entity type (e.g., \"image\").\n",
    "            embeddings_name (str): The name of the embeddings to load.\n",
    "            group_by (str): The column name to group embeddings (e.g., \"well\").\n",
    "            cols_to_keep (list): List of metadata columns to keep.\n",
    "            labels_column (str): The column name used for evaluation labels.\n",
    "            n_neighbors_list (list): A list of neighbor counts for computing lisi.\n",
    "        \"\"\"\n",
    "        self.metadata_path = metadata_path\n",
    "        self.entity = \"image\"\n",
    "        self.embeddings_name = \"chad_dino\"\n",
    "        self.group_by = \"well\"\n",
    "        self.cols_to_keep = [\n",
    "            \"Metadata_JCP2022\",\n",
    "            \"Metadata_InChI\",\n",
    "            \"Metadata_Well\",\n",
    "        ]\n",
    "        self.labels_column = \"Metadata_JCP2022\"\n",
    "        self.n_neighbors_list = [15]\n",
    "\n",
    "        self.em = None\n",
    "        self.em_grouped = None\n",
    "        self.em_filtered = None\n",
    "\n",
    "    def load_embeddings(self, cls_tokens):\n",
    "        \"\"\"\n",
    "        Loads the embeddings using the provided CLS tokens.\n",
    "\n",
    "        Args:\n",
    "            cls_tokens: The CLS tokens extracted from the model.\n",
    "        \"\"\"\n",
    "        self.em = EmbeddingManager(self.metadata_path, entity=self.entity)\n",
    "        self.em.load(self.embeddings_name, cls_tokens)\n",
    "        return self.em\n",
    "\n",
    "    def group_embeddings(self):\n",
    "        \"\"\"\n",
    "        Groups the embeddings by the specified column and keeps selected metadata cols.\n",
    "        \"\"\"\n",
    "        if self.em is None:\n",
    "            raise RuntimeError(\"Embeddings not loaded. Call load_embeddings() first.\")\n",
    "        self.em_grouped = self.em.grouped_embeddings(\n",
    "            group_by=self.group_by,\n",
    "            cols_to_keep=self.cols_to_keep,\n",
    "        )\n",
    "        return self.em_grouped\n",
    "\n",
    "    def apply_transforms(self):\n",
    "        \"\"\"\n",
    "        Applies the spherizing and inverse normalization transforms to the embeddings.\n",
    "        \"\"\"\n",
    "        if self.em_grouped is None:\n",
    "            raise RuntimeError(\n",
    "                \"Grouped embeddings not available. Call group_embeddings() first.\"\n",
    "            )\n",
    "\n",
    "        self.em_grouped.apply_spherizing_transform(\n",
    "            embeddings_name=self.embeddings_name,\n",
    "            new_embeddings_name=f\"{self.embeddings_name}_sph\",\n",
    "            norm_embeddings=False,\n",
    "        )\n",
    "\n",
    "    #    self.em_grouped.apply_inverse_normal_transform(\n",
    "    #        embeddings_name=f\"{self.embeddings_name}_sph\",\n",
    "    #        new_embeddings_name=f\"{self.embeddings_name}_sph_int\",\n",
    "    #    )\n",
    "        return self.em_grouped\n",
    "\n",
    "    def filter_embeddings(self):\n",
    "        \"\"\"\n",
    "        Filters the grouped embeddings using a predefined condition.\n",
    "\n",
    "        \"\"\"\n",
    "        if self.em_grouped is None:\n",
    "            raise RuntimeError(\n",
    "                \"Grouped embeddings not available. Call group_embeddings() first.\"\n",
    "            )\n",
    "\n",
    "        # Use the attribute from the grouped embeddings as a filter condition\n",
    "        self.em_filtered = self.em_grouped.filter_and_instantiate(\n",
    "            **{self.labels_column: self.em_grouped.JCP_ID_poscon}\n",
    "        )\n",
    "        return self.em_filtered\n",
    "\n",
    "    def compute_metrics(self):\n",
    "        \"\"\"\n",
    "        Computes the evaluation metrics (maps and lisi) on the filtered embeddings.\n",
    "\n",
    "        Returns:\n",
    "            tuple: A tuple (maps, lisi) containing the computed metrics.\n",
    "        \"\"\"\n",
    "        if self.em_filtered is None:\n",
    "            raise RuntimeError(\n",
    "                \"Filtered embeddings not available. Call filter_embeddings() first.\"\n",
    "            )\n",
    "\n",
    "        maps = self.em_filtered.compute_maps(\n",
    "            labels_column=self.labels_column,\n",
    "            embeddings_names=f\"{self.embeddings_name}_sph\",\n",
    "        )\n",
    "        lisi = self.em_filtered.compute_lisi(\n",
    "            labels_column=self.labels_column,\n",
    "            embeddings_names=[f\"{self.embeddings_name}_sph\"],\n",
    "            n_neighbors_list=self.n_neighbors_list,\n",
    "        )\n",
    "        return maps[f'mAP ({self.embeddings_name}_sph)'].iloc[-1], lisi[f'{self.embeddings_name}_sph'].iloc[0]\n",
    "\n",
    "    def run_pipeline(self, cls_tokens):\n",
    "        \"\"\"\n",
    "        Runs the complete evaluation pipeline:\n",
    "          1. Load embeddings.\n",
    "          2. Group embeddings.\n",
    "          3. Apply transformations.\n",
    "          4. Filter embeddings.\n",
    "          5. Compute evaluation metrics.\n",
    "\n",
    "        Args:\n",
    "            cls_tokens: The CLS tokens extracted from the model.\n",
    "\n",
    "        Returns:\n",
    "            tuple: The computed metrics (maps, lisi).\n",
    "        \"\"\"\n",
    "        self.load_embeddings(cls_tokens)\n",
    "        self.group_embeddings()\n",
    "        self.apply_transforms()\n",
    "        self.filter_embeddings()\n",
    "        return self.compute_metrics()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "evaluator = EmbeddingsEvaluator(\n",
    "    metadata_path=Path(\"/projects/cpjump1/jump/load_data/test_5_plates.parquet\"),\n",
    ")\n",
    "cls_tokens = np.random.rand(6397, 384).astype(np.float32)\n",
    "maps, lisi = evaluator.run_pipeline(cls_tokens)\n",
    "print(\"MAPs:\", maps)\n",
    "print(\"LISI:\", lisi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lisi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Generate fake CLS tokens for 6397 samples, each of size 384.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.merge(df, on=['Metadata_Well', \"Metadata_Site\", \"Metadata_Batch\", \"Metadata_Plate\"])[['Metadata_Source', 'Metadata_Plate',\n",
    "       'Metadata_Well', 'Metadata_Site', 'Metadata_JCP2022', \n",
    "       'Metadata_InChI', ]].to_parquet(\"/projects/cpjump1/jump/load_data/test_5_plates.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(df_small_meta['Metadata_Plate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plates = set(df_meta[df_meta['Metadata_Source']=='source_6']['Metadata_Plate'])  - set(df_test_meta['Metadata_Plate']) - set(df_small_meta['Metadata_Plate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def select_random_items(plates, n):\n",
    "    \"\"\"\n",
    "    Selects n random items from the given set.\n",
    "\n",
    "    Args:\n",
    "        plates (set): A set of items.\n",
    "        n (int): The number of random items to select.\n",
    "\n",
    "    Returns:\n",
    "        list: A list containing n randomly selected items.\n",
    "    \"\"\"\n",
    "    # Convert the set to a list, then sample n items randomly.\n",
    "    return random.sample(list(plates), n)\n",
    "\n",
    "n = 3\n",
    "random_items = select_random_items(plates, n)\n",
    "print(random_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_meta[df_meta['Metadata_Plate'].isin(random_items)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_parquet(\"/projects/cpjump1/jump/load_data/eval_loader.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load chad img embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path(\"/projects/imagesets4/temp_embeds/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls /projects/imagesets4/temp_embeds/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chad_cls_feats = base_path / Path(\"ctrls_images_chad_dinov2s_cls_embeds.npy\")\n",
    "chad_cls_metadata = base_path / Path(\"ctrls_images_chad_dinov2s_cls_dataframe.parquet\")\n",
    "\n",
    "chad_cls_sm02_feats = base_path / Path(\"ctrls_images_chad_dinov2s_cls_sm02_embeds.npy\")\n",
    "chad_cls_sm02_metadata = base_path / Path(\"ctrls_images_chad_dinov2s_cls_sm02_dataframe.parquet\")\n",
    "\n",
    "chad_cls_sm12x02_w_regs_feats = base_path / Path(\"ctrls_images_chad_dinov2s_cls_sm12x02_w_regs_embeds.npy\")\n",
    "chad_cls_sm12x02_w_regs_metadata = base_path / Path(\"ctrls_images_chad_dinov2s_cls_sm12x02_w_regs_dataframe.parquet\")\n",
    "\n",
    "chad_cls_w_regs_feats = base_path / Path(\"ctrls_images_chad_dinov2s_cls_w_regs_embeds.npy\")\n",
    "chad_cls_w_regs_metadata = base_path / Path(\"ctrls_images_chad_dinov2s_cls_w_regs_dataframe.parquet\")\n",
    "\n",
    "chad_cls_sm02_w_regs_feats = base_path / Path(\"ctrls_images_chad_dinov2s_cls_sm02_w_regs_embeds.npy\")\n",
    "chad_cls_sm02_w_regs_metadata = base_path / Path(\"ctrls_images_chad_dinov2s_cls_sm02_w_regs_dataframe.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chad_em_img = EmbeddingManager(chad_cls_sm02_w_regs_metadata, entity=\"image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chad_em_img.load(\"chad_cls\", chad_cls_feats, chad_cls_metadata)\n",
    "chad_em_img.load(\"chad_cls_sm02\", chad_cls_sm02_feats, chad_cls_sm02_metadata)\n",
    "chad_em_img.load(\"chad_cls_w_regs\", chad_cls_w_regs_feats)\n",
    "chad_em_img.load(\"chad_cls_sm02_w_regs\", chad_cls_sm02_w_regs_feats, chad_cls_sm02_w_regs_metadata)\n",
    "chad_em_img.load(\"chad_cls_sm12x02_w_regs\", chad_cls_sm12x02_w_regs_feats, chad_cls_sm12x02_w_regs_metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chad_em_well = chad_em_img.grouped_embeddings(group_by=\"well\", cols_to_keep=['Metadata_Batch','Metadata_JCP2022', 'Metadata_InChI', \"Metadata_Well\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for model_name in list(chad_em_well.embeddings):\n",
    "    chad_em_well.apply_spherizing_transform(embeddings_name=f\"{model_name}\", new_embeddings_name=f\"{model_name}_sph\", norm_embeddings=False)\n",
    "    chad_em_well.apply_inverse_normal_transform(embeddings_name=f\"{model_name}_sph\", new_embeddings_name=f\"{model_name}_sph_int\")\n",
    "\n",
    "chad_em_well.save_to_folder(Path('/projects/synsight/data/jump_embeddings/wells_embeddings/chad/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add other wells embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for model_name in ['dinov2_s', 'openphenom', 'resnet50', 'chada']:\n",
    "    base_path = Path(f'/projects/synsight/data/jump_embeddings/wells_embeddings/{model_name}')\n",
    "\n",
    "    meta_path_dino = base_path / f'metadata_{model_name}.parquet'\n",
    "    embeddings_path_dino = base_path / f'embeddings_{model_name}.npy'\n",
    "    chad_em_well.load(f\"{model_name}\", embeddings_path_dino, meta_path_dino)\n",
    "\n",
    "    chad_em_well.apply_spherizing_transform(embeddings_name=f\"{model_name}\", new_embeddings_name=f\"{model_name}_sph\", norm_embeddings=False)\n",
    "    chad_em_well.apply_inverse_normal_transform(embeddings_name=f\"{model_name}_sph\", new_embeddings_name=f\"{model_name}_sph_int\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chad_em_well_poscon = chad_em_well.filter_and_instantiate(Metadata_JCP2022=chad_em_well.JCP_ID_poscon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_to_test = [emb_name for emb_name in list(chad_em_well_poscon.embeddings) if \"sph_int\" in emb_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps_source = chad_em_well.compute_maps(labels_column=\"Metadata_Source\", embeddings_names=embeddings_to_test, random_maps=False, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps_jcp = chad_em_well_poscon.compute_maps(labels_column=\"Metadata_JCP2022\", embeddings_names=embeddings_to_test, random_maps=False, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lisi_jcp_2 = chad_em_well_poscon.compute_lisi(labels_column=\"Metadata_JCP2022\", embeddings_names=embeddings_to_test, plot=True, n_neighbors_list=[5, 10, 20, 40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = lisi_jcp_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming your DataFrame is named df\n",
    "# Select only the model columns (those not starting with \"Ideal mixing\")\n",
    "model_columns = [col for col in df.columns if not col.startswith('Ideal mixing')]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for col in model_columns:\n",
    "    plt.plot(df.index, df[col], marker='o', label=col)\n",
    "\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Values\")\n",
    "plt.title(\"Model Values\")\n",
    "\n",
    "# Place the legend outside the plot on the right side\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()  # Adjust layout so nothing is cut off\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming your DataFrame is named df\n",
    "# Select only the model columns (those not starting with \"Ideal mixing\")\n",
    "model_columns = ['chad_cls_sph_int',\n",
    " 'chad_cls_sm02_sph_int',\n",
    " 'chad_cls_w_regs_sph_int',\n",
    " 'chad_cls_sm02_w_regs_sph_int',\n",
    " 'dinov2_s_sph_int',\n",
    " 'chada_sph_int']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for col in model_columns:\n",
    "    plt.plot(df.index, df[col], marker='o', label=col)\n",
    "\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Values\")\n",
    "plt.title(\"Model Values\")\n",
    "\n",
    "# Place the legend outside the plot on the right side\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()  # Adjust layout so nothing is cut off\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('/projects/cpjump1/jump/load_data/final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.merge()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phenoseeker-VFjsjbMc-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
