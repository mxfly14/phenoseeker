{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phenoseeker import BioproxyEvaluator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem.rdFingerprintGenerator import GetMorganGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path(\"/home/maxime/data/jump_embeddings/dinov2_g/compounds/\")\n",
    "npy_file = base_path  / \"Embeddings_norm.npy\"\n",
    "parquet_metadata = base_path  / Path(\"metadata.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "screens_folders = {\n",
    "      #  \"ChemBL\": Path(\"/projects/synsight/repos/phenospace/bioproxy/screens_data_chembl\"),\n",
    "        \"Curie\": Path(\"/projects/synsight/repos/phenospace/bioproxy/screens_data_curie\"),\n",
    "        \"ChEMBL\": Path(\"/projects/synsight/repos/phenoseeker/data/ChEMBL/assays_csv\"),\n",
    "        \"Lit-PCBA\": Path(\"/projects/synsight/repos/phenoseeker/data/Lit_PCBA/csv_files\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval = BioproxyEvaluator(parquet_metadata, npy_file, screens_folders, embeddings_name='Embeddings_dinov2', embeddings_entity='compound')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eval.compute_distance_matrix(embeddings_cols=[\"Embeddings_dinov2\"], distance='cosine')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "     \n",
    "for source in eval.screens_data.keys():\n",
    "    for screen in eval.screens_data[source].keys():\n",
    "        eval.distance_matrices[source][screen]['Embeddings_mean'] = 1 - eval.distance_matrices[source][screen]['Embeddings_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for source in eval.screens_data.keys():\n",
    "    for screen in eval.screens_data[source].keys():\n",
    "        eval.distance_matrices[source][screen]['Embeddings_mean'] = 1 - eval.distance_matrices[source][screen]['Embeddings_mean']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tanimono(df):\n",
    "    inchi_list = df[\"Metadata_InChI\"].tolist()\n",
    "    tanimoto = []\n",
    "    mols = [Chem.MolFromInchi(inchi) for inchi in inchi_list]\n",
    "    gen = GetMorganGenerator(radius=2, fpSize=2048)\n",
    "    fps = [gen.GetFingerprint(mol) for mol in mols]\n",
    "    for fp in fps:\n",
    "        sim = DataStructs.TanimotoSimilarity(fps[0], fp)\n",
    "        tanimoto.append(sim)\n",
    "    return tanimoto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sims(df):\n",
    "    df_excluded = df.iloc[1:]\n",
    "    n_first_5_percent = int(len(df_excluded) * 0.05) + 1\n",
    "    mean_tanimoto_first_5_percent = df_excluded.nsmallest(n_first_5_percent, 'Distance')['tanimoto_to_target'].mean()\n",
    "    mean_tanimoto_last_5_percent = df_excluded.nlargest(n_first_5_percent, 'tanimoto_to_target')['tanimoto_to_target'].mean()\n",
    "    mean_tanimoto_all = df_excluded['tanimoto_to_target'].mean()\n",
    "    return mean_tanimoto_first_5_percent, mean_tanimoto_last_5_percent, mean_tanimoto_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_sims(source, screen, eval):\n",
    "    df_inchi = eval.screens_data[source][screen][['Metadata_JCP2022' ,'Metadata_InChI']].drop_duplicates()\n",
    "    best_jcp = eval.calculate_enrichment_factor(source, screen, 'Embeddings_mean', [5]).sort_values(by='EF', ascending=False).iloc[0]['Metadata_JCP2022']\n",
    "    res_dic = pd.DataFrame(eval.compute_ranking(source, screen, 'Embeddings_mean', best_jcp,  plot=False))\n",
    "    df = res_dic.merge(df_inchi, on='Metadata_JCP2022').drop_duplicates()\n",
    "    df['tanimoto_to_target'] = get_tanimono(df)\n",
    "    return calculate_sims(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = 'Curie'\n",
    "screen = 'E15'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sims(source, screen, eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_means_Curie = []\n",
    "high_5_means_Curie = []\n",
    "all_means_Curie = []\n",
    "\n",
    "# Assuming `eval` and `get_sims` are predefined\n",
    "for source in [\"Curie\"]:  # Add 'ChemBL' if needed\n",
    "    for screen in tqdm(eval.screens_data[source].keys()):\n",
    "        top_5, high_5, all_mean = get_sims(source, screen, eval)\n",
    "        top_5_means_Curie.append(top_5)\n",
    "        high_5_means_Curie.append(high_5)\n",
    "        all_means_Curie.append(all_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_means_ChemBL = []\n",
    "high_5_means_ChemBL = []\n",
    "all_means_ChemBL = []\n",
    "\n",
    "# Assuming `eval` and `get_sims` are predefined\n",
    "for source in [\"ChemBL\"]:  # Add 'ChemBL' if needed\n",
    "    for screen in tqdm(eval.screens_data[source].keys()):\n",
    "        top_5, high_5, all_mean = get_sims(source, screen, eval)\n",
    "        top_5_means_ChemBL.append(top_5)\n",
    "        high_5_means_ChemBL.append(high_5)\n",
    "        all_means_ChemBL.append(all_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import shapiro, ttest_rel, wilcoxon\n",
    "\n",
    "# Your three lists (ensure they are of equal length and correspond element-wise)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "all_means = np.array(all_means_Curie)\n",
    "top_5_means = np.array(top_5_means_Curie)\n",
    "high_5_means = np.array(high_5_means_Curie)\n",
    "\n",
    "# Ensure that all arrays have the same length\n",
    "assert len(all_means) == len(top_5_means) == len(high_5_means), \"Arrays must be of the same length\"\n",
    "\n",
    "# Compute differences between paired samples\n",
    "diff_high_all = high_5_means - all_means\n",
    "diff_high_top = high_5_means - top_5_means\n",
    "\n",
    "# Step 1: Check for normality of differences\n",
    "alpha = 0.05  # Significance level\n",
    "\n",
    "# Test normality for high_5_means vs. all_means\n",
    "stat_high_all, p_high_all = shapiro(diff_high_all)\n",
    "print(\"Normality Test for High 5% vs. All Means Differences:\")\n",
    "print(f\"Shapiro-Wilk Test Statistic: {stat_high_all:.10f}, p-value: {p_high_all:.10f}\")\n",
    "\n",
    "# Test normality for high_5_means vs. top_5_means\n",
    "stat_high_top, p_high_top = shapiro(diff_high_top)\n",
    "print(\"\\nNormality Test for High 5% vs. Top 5% Means Differences:\")\n",
    "print(f\"Shapiro-Wilk Test Statistic: {stat_high_top:.10f}, p-value: {p_high_top:.10f}\")\n",
    "\n",
    "# Decide which test to use based on normality\n",
    "# Comparison 1: High 5% vs. All Means\n",
    "if p_high_all > alpha:\n",
    "    # Differences are normally distributed; use paired t-test\n",
    "    t_statistic, p_value = ttest_rel(high_5_means, all_means, alternative='greater')\n",
    "    print(\"\\nPaired t-test for High 5% vs. All Means:\")\n",
    "else:\n",
    "    # Differences are not normally distributed; use Wilcoxon signed-rank test\n",
    "    t_statistic, p_value = wilcoxon(high_5_means, all_means, alternative='greater', zero_method='wilcox')\n",
    "    print(\"\\nWilcoxon signed-rank test for High 5% vs. All Means:\")\n",
    "\n",
    "print(f\"Test Statistic: {t_statistic:.10f}, p-value: {p_value:.10f}\")\n",
    "\n",
    "# Interpretation\n",
    "if p_value < alpha:\n",
    "    print(\"Result: Statistically significant difference (High 5% > All Means)\")\n",
    "else:\n",
    "    print(\"Result: No statistically significant difference\")\n",
    "\n",
    "# Comparison 2: High 5% vs. Top 5% Means\n",
    "if p_high_top > alpha:\n",
    "    # Differences are normally distributed; use paired t-test\n",
    "    t_statistic, p_value = ttest_rel(high_5_means, top_5_means, alternative='greater')\n",
    "    print(\"\\nPaired t-test for High 5% vs. Top 5% Means:\")\n",
    "else:\n",
    "    # Differences are not normally distributed; use Wilcoxon signed-rank test\n",
    "    t_statistic, p_value = wilcoxon(high_5_means, top_5_means, alternative='greater', zero_method='wilcox')\n",
    "    print(\"\\nWilcoxon signed-rank test for High 5% vs. Top 5% Means:\")\n",
    "\n",
    "print(f\"Test Statistic: {t_statistic:.10f}, p-value: {p_value:.10f}\")\n",
    "\n",
    "# Interpretation\n",
    "if p_value < alpha:\n",
    "    print(\"Result: Statistically significant difference (High 5% > Top 5% Means)\")\n",
    "else:\n",
    "    print(\"Result: No statistically significant difference\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import wilcoxon\n",
    "def assign_stars(p_value):\n",
    "    if p_value < 0.00001:\n",
    "        return \"*****\"\n",
    "    elif p_value < 0.0001:\n",
    "        return \"****\"\n",
    "    elif p_value < 0.001:\n",
    "        return \"***\"\n",
    "    elif p_value < 0.01:\n",
    "        return \"**\"\n",
    "    elif p_value < 0.05:\n",
    "        return \"*\"\n",
    "    else:\n",
    "        return \"ns\"\n",
    "\n",
    "# Perform pairwise Wilcoxon signed-rank tests\n",
    "alpha = 0.05  # Significance level\n",
    "labels = ['Across all Compounds', '5% Most Similar Phenotypes', '5% Most Similar Structure']\n",
    "colors = ['skyblue', 'lightgreen', 'salmon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_5_means = high_5_means_Curie\n",
    "all_means = all_means_Curie\n",
    "top_5_means = top_5_means_Curie\n",
    "\n",
    "data = [all_means, top_5_means, high_5_means]\n",
    "\n",
    "# High 5% vs. All Means\n",
    "stat_high_vs_all, p_high_vs_all = wilcoxon(high_5_means, all_means, alternative='greater')\n",
    "significance_high_vs_all = assign_stars(p_high_vs_all)\n",
    "\n",
    "# High 5% vs. Top 5% Means\n",
    "stat_high_vs_top, p_high_vs_top = wilcoxon(high_5_means, top_5_means, alternative='greater')\n",
    "significance_high_vs_top = assign_stars(p_high_vs_top)\n",
    "\n",
    "# Top 5% vs. All Means\n",
    "stat_top_vs_all, p_top_vs_all = wilcoxon(top_5_means, all_means, alternative='greater')\n",
    "significance_top_vs_all =assign_stars(p_top_vs_all)\n",
    "\n",
    "plt.figure(figsize=(4, 10))\n",
    "box = plt.boxplot(data, labels=labels, patch_artist=True, showmeans=True)\n",
    "\n",
    "# Apply colors to the boxes\n",
    "for patch, color in zip(box['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.7)\n",
    "\n",
    "# Overlay the points\n",
    "for i, (dataset, color) in enumerate(zip(data, colors), start=1):\n",
    "    plt.scatter([i] * len(dataset), dataset, color=color, alpha=0.7, edgecolor='k')\n",
    "\n",
    "# Add significance stars between specific pairs\n",
    "y_max_all_top5 = max(max(all_means), max(top_5_means)) + 0.01  # Level for All vs. Top 5%\n",
    "y_max_top5_high5 = max(max(top_5_means), max(high_5_means))  # Level for Top 5% vs. High 5%\n",
    "h = 0.01  # Height above the maximum for the stars\n",
    "star_offset = 0.002  # Vertical spacing between the significance lines and stars\n",
    "\n",
    "# Add significance between All and Top 5%\n",
    "x1, x2 = 1, 2\n",
    "plt.plot([x1, x1, x2, x2], [y_max_all_top5, y_max_all_top5 + h, y_max_all_top5 + h, y_max_all_top5], lw=1.5, color='black')\n",
    "plt.text((x1 + x2) * 0.5, y_max_all_top5 + h + star_offset, significance_top_vs_all, ha='center', fontsize=12)\n",
    "plt.ylim(0.03, 0.47)\n",
    "# Add significance between Top 5% and High 5%\n",
    "x1, x2 = 2, 3\n",
    "plt.plot([x1, x1, x2, x2], [y_max_top5_high5 + h, y_max_top5_high5 + 2 * h, y_max_top5_high5 + 2 * h, y_max_top5_high5 + h], lw=1.5, color='black')\n",
    "plt.text((x1 + x2) * 0.5, y_max_top5_high5 + 2 * h + star_offset, significance_high_vs_top, ha='center', fontsize=12)\n",
    "\n",
    "# Add plot details\n",
    "plt.ylabel('Tanimoto Similarity')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_5_means = high_5_means_ChemBL\n",
    "all_means = all_means_ChemBL\n",
    "top_5_means = top_5_means_ChemBL\n",
    "data = [all_means, top_5_means, high_5_means]\n",
    "\n",
    "# High 5% vs. All Means\n",
    "stat_high_vs_all, p_high_vs_all = wilcoxon(high_5_means, all_means, alternative='greater')\n",
    "significance_high_vs_all = assign_stars(p_high_vs_all)\n",
    "\n",
    "# High 5% vs. Top 5% Means\n",
    "stat_high_vs_top, p_high_vs_top = wilcoxon(high_5_means, top_5_means, alternative='greater')\n",
    "significance_high_vs_top = assign_stars(p_high_vs_top)\n",
    "\n",
    "# Top 5% vs. All Means\n",
    "stat_top_vs_all, p_top_vs_all = wilcoxon(top_5_means, all_means, alternative='greater')\n",
    "significance_top_vs_all =assign_stars(p_top_vs_all)\n",
    "\n",
    "plt.figure(figsize=(4, 10))\n",
    "box = plt.boxplot(data, labels=labels, patch_artist=True, showmeans=True)\n",
    "\n",
    "# Apply colors to the boxes\n",
    "for patch, color in zip(box['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.7)\n",
    "\n",
    "# Overlay the points\n",
    "for i, (dataset, color) in enumerate(zip(data, colors), start=1):\n",
    "    plt.scatter([i] * len(dataset), dataset, color=color, alpha=0.7, edgecolor='k')\n",
    "\n",
    "# Add significance stars between specific pairs\n",
    "y_max_all_top5 = max(max(all_means), max(top_5_means)) + 0.01  # Level for All vs. Top 5%\n",
    "y_max_top5_high5 = max(max(top_5_means), max(high_5_means))  # Level for Top 5% vs. High 5%\n",
    "h = 0.01  # Height above the maximum for the stars\n",
    "star_offset = 0.002  # Vertical spacing between the significance lines and stars\n",
    "\n",
    "# Add significance between All and Top 5%\n",
    "x1, x2 = 1, 2\n",
    "plt.plot([x1, x1, x2, x2], [y_max_all_top5, y_max_all_top5 + h, y_max_all_top5 + h, y_max_all_top5], lw=1.5, color='black')\n",
    "plt.text((x1 + x2) * 0.5, y_max_all_top5 + h + star_offset, significance_top_vs_all, ha='center', fontsize=12)\n",
    "plt.ylim(0.03, 0.47)\n",
    "# Add significance between Top 5% and High 5%\n",
    "x1, x2 = 2, 3\n",
    "plt.plot([x1, x1, x2, x2], [y_max_top5_high5 + h, y_max_top5_high5 + 2 * h, y_max_top5_high5 + 2 * h, y_max_top5_high5 + h], lw=1.5, color='black')\n",
    "plt.text((x1 + x2) * 0.5, y_max_top5_high5 + 2 * h + star_offset, significance_high_vs_top, ha='center', fontsize=12)\n",
    "\n",
    "# Add plot details\n",
    "plt.ylabel('Tanimoto Similarity')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phenoseeker-VFjsjbMc-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
