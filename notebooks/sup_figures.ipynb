{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"dinov2_g\"\n",
    "base_path = Path(\"/projects/synsight/data/jump_embeddings/compounds_embeddings/\")\n",
    "parquet_metadata = base_path / model / Path(\"metadata.parquet\")\n",
    "jump_df = pd.read_parquet(parquet_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Chemical Space Coverance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# Détection automatique du délimiteur\n",
    "file_path_1 = \"/projects/synsight/repos/phenoseeker/data/DOWNLOAD-Z1ne6qrt4wu91Pko505qNL8HRHmP9w9SFGyvEarzIcM=.csv\"\n",
    "file_path_2 = \"/projects/synsight/repos/phenoseeker/data/DOWNLOAD-Z1ne6qrt4wu91Pko505qNL8HRHmP9w9SFGyvEarzIcM=_part2.csv\"\n",
    "\n",
    "with open(file_path_2, \"r\", encoding=\"utf-8\") as f:\n",
    "    sample = f.read(1024)\n",
    "    sniffer = csv.Sniffer()\n",
    "    dialect = sniffer.sniff(sample)\n",
    "    print(\"Délimiteur détecté :\", dialect.delimiter)\n",
    "\n",
    "# Lecture du CSV en spécifiant le délimiteur et en utilisant l'engine Python\n",
    "try:\n",
    "    df_chembl_1 = pd.read_csv(\n",
    "        file_path_1,\n",
    "        delimiter=dialect.delimiter,\n",
    "        engine=\"python\",\n",
    "        on_bad_lines=\"skip\",  # ou 'warn' pour simplement avertir\n",
    "        encoding=\"utf-8\"\n",
    "    )\n",
    "    df_chembl_2 = pd.read_csv(\n",
    "        file_path_2,\n",
    "        delimiter=dialect.delimiter,\n",
    "        engine=\"python\",\n",
    "        on_bad_lines=\"skip\",  # ou 'warn' pour simplement avertir\n",
    "        encoding=\"utf-8\"\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Erreur lors de la lecture du fichier CSV :\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, DataStructs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import umap.umap_ as umap\n",
    "\n",
    "##############################\n",
    "# Fonctions de calcul d'empreintes\n",
    "##############################\n",
    "def get_morgan_fp(inchi, radius=2, nBits=2048):\n",
    "    \"\"\"Calcule l'empreinte Morgan à partir d'un InChI (chaîne).\"\"\"\n",
    "    mol = Chem.MolFromInchi(inchi)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=nBits)\n",
    "    arr = np.zeros((nBits,), dtype=int)\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    return arr\n",
    "\n",
    "def get_morgan_fp_from_mol(mol, radius=2, nBits=2048):\n",
    "    \"\"\"Calcule l'empreinte Morgan à partir d'un objet Mol RDKit.\"\"\"\n",
    "    if mol is None:\n",
    "        return None\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=nBits)\n",
    "    arr = np.zeros((nBits,), dtype=int)\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    return arr\n",
    "\n",
    "##############################\n",
    "# Fonctions de sampling\n",
    "##############################\n",
    "def uniform_sample(df, n=5000, random_state=42):\n",
    "    \"\"\"Sampling uniforme : on prend au maximum n molécules par dataset.\"\"\"\n",
    "    if len(df) > n:\n",
    "        return df.sample(n=n, random_state=random_state)\n",
    "    else:\n",
    "        return df\n",
    "\n",
    "def proportional_sample(df, frac=0.1,random_state=42):\n",
    "    \"\"\"Sampling proportionnel : on prend une fraction (ici 10%) du dataset.\"\"\"\n",
    "    return df.sample(frac=frac, random_state=random_state)\n",
    "\n",
    "\n",
    "def plot_umap(df, title, shuffle_points=True):\n",
    "    \"\"\"\n",
    "    Compute the UMAP embedding from molecular fingerprints and display the projection.\n",
    "    \n",
    "    Parameters:\n",
    "      df: DataFrame containing at least columns \"fp\" (fingerprint) and \"dataset\"\n",
    "      title: Title for the plot.\n",
    "      shuffle_points: If True, randomly shuffles the rows. If False, orders the points\n",
    "                      starting with the dataset having the most compounds and ending with \n",
    "                      the one with the fewest compounds.\n",
    "    \"\"\"\n",
    "    if shuffle_points:\n",
    "        df_ordered = df.copy().sample(frac=1, random_state=42)\n",
    "    else:\n",
    "        # Order rows by dataset size (largest first)\n",
    "        df_ordered = df.copy()\n",
    "        ds_counts = df_ordered['dataset'].value_counts()\n",
    "        df_ordered['ds_count'] = df_ordered['dataset'].map(ds_counts)\n",
    "        df_ordered = df_ordered.sort_values(by='ds_count', ascending=False)\n",
    "        df_ordered = df_ordered.drop(columns=['ds_count'])\n",
    "    \n",
    "    # Compute UMAP embedding from the fingerprint matrix.\n",
    "    X = np.vstack(df_ordered[\"fp\"].values)\n",
    "    reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, metric='jaccard', random_state=42)\n",
    "    embedding = reducer.fit_transform(X)\n",
    "    df_ordered[\"umap_x\"] = embedding[:, 0]\n",
    "    df_ordered[\"umap_y\"] = embedding[:, 1]\n",
    "    \n",
    "    # Define a stable ordering for the dataset names\n",
    "    categories = sorted(df_ordered[\"dataset\"].unique())\n",
    "    \n",
    "    # Create a color mapping for each dataset.\n",
    "    color_dict = {}\n",
    "    if len(categories) > 1:\n",
    "        for i, cat in enumerate(categories):\n",
    "            color_dict[cat] = plt.cm.viridis(i / (len(categories) - 1))\n",
    "    else:\n",
    "        color_dict[categories[0]] = plt.cm.viridis(0.5)\n",
    "    \n",
    "    # Map each row's dataset to its color.\n",
    "    df_ordered[\"color\"] = df_ordered[\"dataset\"].map(color_dict)\n",
    "    \n",
    "    # Plot the UMAP projection.\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.scatter(df_ordered[\"umap_x\"], df_ordered[\"umap_y\"],\n",
    "                c=df_ordered[\"color\"], alpha=0.6, s=10)\n",
    "    \n",
    "    # Build a legend that matches each dataset to its color.\n",
    "    handles = [\n",
    "        plt.Line2D([0], [0], marker='o', color='w',\n",
    "                   label=cat, markerfacecolor=color_dict[cat], markersize=10)\n",
    "        for cat in categories\n",
    "    ]\n",
    "    plt.legend(handles=handles, title=\"Dataset\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"UMAP 1\")\n",
    "    plt.ylabel(\"UMAP 2\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def compute_fp(row):\n",
    "    \"\"\"Calcule l'empreinte en fonction du type de dataset.\"\"\"\n",
    "    if row[\"dataset\"] == \"DrugBank\":\n",
    "        # Pour DrugBank, utiliser l'objet Mol directement\n",
    "        return get_morgan_fp_from_mol(row[\"mol\"])\n",
    "    else:\n",
    "        # Pour JUMP-CP et ChemBL, utiliser la colonne 'inchi'\n",
    "        return get_morgan_fp(row[\"inchi\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##############################\n",
    "# 1. Chargement du dataset JUMP-CP\n",
    "##############################\n",
    "df_jump = jump_df.copy(deep=True)\n",
    "df_jump = df_jump.rename(columns={\"Metadata_InChI\": \"inchi\"})\n",
    "df_jump[\"dataset\"] = \"JUMP-CP\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##############################\n",
    "# 2. Chargement de DrugBank à partir d'un multi SDF\n",
    "##############################\n",
    "drugbank_file = \"/projects/synsight/repos/phenoseeker/data/open structures.sdf\"  # Chemin vers votre fichier DrugBank SDF\n",
    "supplier = Chem.SDMolSupplier(drugbank_file)\n",
    "drugbank_data = []\n",
    "for mol in supplier:\n",
    "    if mol is None:\n",
    "        continue\n",
    "    # Optionnel : récupération du SMILES pour vérification\n",
    "    smiles = Chem.MolToSmiles(mol)\n",
    "    drugbank_data.append({\"mol\": mol, \"smiles\": smiles})\n",
    "df_drugbank = pd.DataFrame(drugbank_data)\n",
    "df_drugbank[\"dataset\"] = \"DrugBank\"\n",
    "# Note : Pour DrugBank, nous utiliserons l'objet Mol directement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##############################\n",
    "# 3. Chargement des fichiers ChemBL et fusion\n",
    "##############################\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# Détection automatique du délimiteur\n",
    "file_path_1 = \"/projects/synsight/repos/phenoseeker/data/DOWNLOAD-Z1ne6qrt4wu91Pko505qNL8HRHmP9w9SFGyvEarzIcM=.csv\"\n",
    "file_path_2 = \"/projects/synsight/repos/phenoseeker/data/DOWNLOAD-Z1ne6qrt4wu91Pko505qNL8HRHmP9w9SFGyvEarzIcM=_part2.csv\"\n",
    "\n",
    "with open(file_path_2, \"r\", encoding=\"utf-8\") as f:\n",
    "    sample = f.read(1024)\n",
    "    sniffer = csv.Sniffer()\n",
    "    dialect = sniffer.sniff(sample)\n",
    "    print(\"Délimiteur détecté :\", dialect.delimiter)\n",
    "\n",
    "# Lecture du CSV en spécifiant le délimiteur et en utilisant l'engine Python\n",
    "try:\n",
    "    df_chembl_1 = pd.read_csv(\n",
    "        file_path_1,\n",
    "        delimiter=dialect.delimiter,\n",
    "        engine=\"python\",\n",
    "        on_bad_lines=\"skip\",  # ou 'warn' pour simplement avertir\n",
    "        encoding=\"utf-8\"\n",
    "    )\n",
    "    df_chembl_2 = pd.read_csv(\n",
    "        file_path_2,\n",
    "        delimiter=dialect.delimiter,\n",
    "        engine=\"python\",\n",
    "        on_bad_lines=\"skip\",  # ou 'warn' pour simplement avertir\n",
    "        encoding=\"utf-8\"\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Erreur lors de la lecture du fichier CSV :\", e)\n",
    "\n",
    "# Standardiser la colonne InChI\n",
    "df_chembl1 = df_chembl_1.rename(columns={\"Inchi\": \"inchi\"})\n",
    "df_chembl2 = df_chembl_2.rename(columns={\"Inchi\": \"inchi\"})\n",
    "df_chembl = pd.concat([df_chembl1, df_chembl2], ignore_index=True)\n",
    "df_chembl[\"dataset\"] = \"ChemBL\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##############################\n",
    "# 4. Réalisation des samplings\n",
    "##############################\n",
    "\n",
    "random_state = 2\n",
    "\n",
    "# Sampling uniforme : maximum de 5000 molécules par dataset\n",
    "df_jump_uniform = uniform_sample(df_jump, n=5000, random_state=random_state)\n",
    "df_drugbank_uniform = uniform_sample(df_drugbank, n=5000, random_state=random_state)\n",
    "df_chembl_uniform = uniform_sample(df_chembl, n=5000, random_state=random_state)\n",
    "\n",
    "# Sampling proportionnel : 10% de chaque dataset\n",
    "df_jump_prop = proportional_sample(df_jump, frac=0.01, random_state=random_state)\n",
    "df_drugbank_prop = proportional_sample(df_drugbank, frac=0.01, random_state=random_state)\n",
    "df_chembl_prop = proportional_sample(df_chembl, frac=0.01, random_state=random_state)\n",
    "\n",
    "# Concaténer pour chaque stratégie\n",
    "df_uniform = pd.concat([df_jump_uniform, df_drugbank_uniform, df_chembl_uniform], ignore_index=True)\n",
    "df_proportional = pd.concat([df_jump_prop, df_drugbank_prop, df_chembl_prop], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##############################\n",
    "# 5. Calcul des empreintes pour chaque échantillon\n",
    "##############################\n",
    "def compute_fp(row):\n",
    "    \"\"\"Calcule l'empreinte en fonction du type de dataset.\"\"\"\n",
    "    if row[\"dataset\"] == \"DrugBank\":\n",
    "        # Pour DrugBank, utiliser l'objet Mol directement\n",
    "        try:\n",
    "            return get_morgan_fp_from_mol(row[\"mol\"])\n",
    "        except Exception as e:\n",
    "            return None\n",
    "    else:\n",
    "        # Pour JUMP-CP et ChemBL, utiliser la colonne 'inchi'\n",
    "        inchi = row[\"inchi\"]\n",
    "        # Vérifier que l'InChI est bien une chaîne de caractères\n",
    "        if not isinstance(inchi, str):\n",
    "            return None\n",
    "        try:\n",
    "            return get_morgan_fp(inchi)\n",
    "        except Exception as e:\n",
    "            return None\n",
    "# Pour le sampling uniforme\n",
    "df_uniform[\"fp\"] = df_uniform.apply(compute_fp, axis=1)\n",
    "df_uniform = df_uniform[df_uniform[\"fp\"].notnull()].reset_index(drop=True)\n",
    "\n",
    "# Pour le sampling proportionnel\n",
    "df_proportional[\"fp\"] = df_proportional.apply(compute_fp, axis=1)\n",
    "df_proportional = df_proportional[df_proportional[\"fp\"].notnull()].reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##############################\n",
    "# 6. Projection UMAP et visualisation\n",
    "##############################\n",
    "\n",
    "# Affichage UMAP pour sampling uniforme\n",
    "plot_umap(df_uniform, \"UMAP - Uniforme Sampling (5000 compounds per dataset)\")\n",
    "\n",
    "# Affichage UMAP pour sampling proportionnel (10% de chaque dataset)\n",
    "plot_umap(df_proportional, \"UMAP - Proportionnal Sampling (1% of each dataset)\",  False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##############################\n",
    "# 6. Projection UMAP et visualisation\n",
    "##############################\n",
    "\n",
    "# Affichage UMAP pour sampling uniforme\n",
    "plot_umap(df_uniform, \"UMAP - Uniforme Sampling (5000 compounds per dataset)\")\n",
    "\n",
    "# Affichage UMAP pour sampling proportionnel (10% de chaque dataset)\n",
    "plot_umap(df_proportional, \"UMAP - Proportionnal Sampling (1% of each dataset)\",  False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##############################\n",
    "# 6. Projection UMAP et visualisation\n",
    "##############################\n",
    "\n",
    "# Affichage UMAP pour sampling uniforme\n",
    "plot_umap(df_uniform, \"UMAP - Uniforme Sampling (5000 compounds per dataset)\")\n",
    "\n",
    "# Affichage UMAP pour sampling proportionnel (10% de chaque dataset)\n",
    "plot_umap(df_proportional, \"UMAP - Proportionnal Sampling (1% of each dataset)\",  False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
